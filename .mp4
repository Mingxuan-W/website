<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- <meta property='og:title' content="Jessica Bo | Personal Website"/> -->
  <!-- <meta property='og:image' content="img/mountains_preview.png"/> -->

  <title>Yael Vinker</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Custom fonts for this theme -->
  <link href="vendor/fontawesome-free/css/all.min.css" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Dosis:400,700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

  <!-- Favicons -->
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
  <link rel="icon" href="favicon.ico" type="image/x-icon">

  <!-- Theme CSS -->
  <link href="css/freelancer.css" rel="stylesheet">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg bg-secondary fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="index.html">Yael Vinker</a>
      <button class="navbar-toggler navbar-toggler-right text-uppercase bg-secondary text-white rounded" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        Menu
        <i class="fas fa-bars"></i>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item mx-0 mx-lg-1">
            <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger large" href="about.html">About</a>
          </li>
          <li class="nav-item mx-0 mx-lg-1">
            <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger large" href="art.html">Art</a>
          </li>
          <li class="nav-item mx-0 mx-lg-1">
            <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger large" href="research.html">Research</a>
          </li>
           <li class="nav-item mx-0 mx-lg-1">
            <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger large" href="talks.html">Talks</a>
          </li>
          <!-- <li class="nav-item mx-0 mx-lg-1">
            <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger large" href="portfolio.html">Sculpting</a>
          </li> -->
        </ul>
      </div>
    </div>
  </nav>


  <!-- Portfolio Section -->
  <section class="page-section portfolio" id="portfolio">
    <div class="container">

      <!-- Portfolio Section Heading -->
      <h1 class="page-section-heading text-center text-uppercase mb-6">Projects</h1>

      <!-- <h4 class="mt-6">> <highlight>Robotics & Vision</highlight></h4> -->

      
      <div class="row mb-6">
        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#wordasimage">
            <img class="img-fluid" src="img/portfolio/word-as-image_teaser.png" alt="">
          </div>
          <div class="portfolio-label">Word-As-Image for Semantic Typography</div>
          <div class="portfolio-authors">Shir Iluz*, <b>Yael Vinker*</b>, Amir Hertz, Daniel Berio, Daniel Cohen-Or, Ariel Shamir</div>
          <div class="portfolio-subtitle">SIGGRAPH 2023</div>
        </div>

        <div class="row mb-6">
        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#attend&excite">
            <img class="img-fluid" src="img/portfolio/attend_and_excite_teaser.jpg" alt="">
          </div>
          <div class="portfolio-label">Attend-and-Excite: Attention-Based Semantic Guidance for <br>Text-to-Image Diffusion Models</div>
          <div class="portfolio-authors">Hila Chefer*, Yuval Alaluf*, <b>Yael Vinker</b>, Lior Wolf, Daniel Cohen-Or</div>
          <div class="portfolio-subtitle">SIGGRAPH 2023</div>
        </div>


      <div class="row mb-6">
        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#clipascene">
            
            <img class="img-fluid" src="img/portfolio/clipascene_teaser2.jpg" alt="">
          </div>
          <div class="portfolio-label">CLIPascene: Scene Sketching with Different Types <br> and Levels of Abstraction</div>
          <div class="portfolio-authors"><b>Yael Vinker</b>, Yuval Alaluf, Daniel Cohen-Or, Ariel Shamir</div>
          <!-- <div class="portfolio-subtitle">SIGGRAPH 2022, <highlight>Best Paper Award</highlight></div> -->
        </div>
        

      <div class="row mb-6">
        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#clipasso">
            <div class="portfolio-item-caption h-100 w-100">
              <!-- <div class="portfolio-item-caption-content text-center">
                <p>Wheelchair detection and orientation classification for mobile robots.</p>
              </div> -->
            </div>
            <img class="img-fluid" src="img/portfolio/teaser2.png" alt="">
          </div>
          <div class="portfolio-label">CLIPasso: Semantically-Aware Object Sketching</div>
          <div class="portfolio-authors"><b>Yael Vinker</b>, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Bachmann, <br>Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir</div>
          <div class="portfolio-subtitle">SIGGRAPH 2022, <highlight>Best Paper Award</highlight></div>

          
          <!-- <div class="portfolio-skill">Our work converts an image of an object to a sketch, allowing for varying levels of abstraction, while preserving its key visual features.</div> -->
        </div>
        


        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#deepsim">
            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
              <div class="portfolio-item-caption-content text-center">
                <!-- <p>Point cloud registration experiments with the HoloLens.</p> -->
              </div>
            </div>
            <img class="img-fluid" src="img/portfolio/deepsim.png" alt="">
          </div>
          <div class="portfolio-label">DeepSIM: Image Shape Manipulation from a Single <br> Augmented Training Sample</div>
          <div class="portfolio-authors"><b>Yael Vinker*</b>, Eliahu Horwitz*, Nir Zabari , Yedid Hoshen</div>
          <div class="portfolio-subtitle">ICCV 2021, <highlight>Oral Presentation</highlight></div>
        </div>

        <div class="col-md-10 col-lg-10">
          <div class="portfolio-item portfolio-item-research mx-auto" data-toggle="modal" data-target="#hdr">
            <div class="portfolio-item-caption d-flex align-items-center justify-content-center h-100 w-100">
              <div class="portfolio-item-caption-content text-center">
                <!-- <p>Point cloud registration experiments with the HoloLens.</p> -->
              </div>
            </div>
            <img class="img-fluid" src="research/hdr/teaser1_hdr.png" alt="">
          </div>
          <div class="portfolio-label">Unpaired Learning for High Dynamic Range Image Tone Mapping</div>
          <div class="portfolio-authors"><b>Yael Vinker</b>, Inbar Huberman-Spiegelglas, Raanan Fattal</div>
          <div class="portfolio-subtitle">ICCV 2021</div>
        </div>

    </div>
  </section>

<div class="portfolio-modal modal fade" id="wordasimage" tabindex="-1" role="dialog" aria-labelledby="wordasimage" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Word-As-Image for Semantic Typography</h1>
                <p class="font-italic mb-3">Shir Iluz*, <b>Yael Vinker*</b>, Amir Hertz, Daniel Berio, Daniel Cohen-Or, Ariel Shamir</p>
                
                <div class="video-container mb-4">
                  <video width="100%" height="auto" id="tree" autoplay controls>
                    <source src="img/portfolio/word-as-image-video.mp4"
                    type="video/mp4">
                  </video>
                </div>
               
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">A word-as-image is a semantic typography technique where a word illustration presents a visualization of the meaning of the word, while also preserving its readability. We present a method to create word-as-image illustrations automatically. This task is highly challenging as it requires semantic understanding of the word and a creative idea of where and how to depict these semantics in a visually pleasing and legible manner. We rely on the remarkable ability of recent large pretrained language-vision models to distill textual concepts visually. We target simple, concise, black-and-white designs that convey the semantics clearly. We deliberately do not change the color or texture of the letters and do not use embellishments. Our method optimizes the outline of each letter to convey the desired concept, guided by a pretrained Stable Diffusion model. We incorporate additional loss terms to ensure the legibility of the text and the preservation of the style of the font. We show high quality and engaging results on numerous examples and compare to alternative techniques.
                 </p>
                <div class="large mb-2 font-weight-bold">
                  <a href="https://wordasimage.github.io/Word-As-Image-Page/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://arxiv.org/abs/2303.01818" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                </div>
              
                <div class="large mb-2 font-weight-bold">
                  <a href="https://github.com/Shiriluz/Word-As-Image" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://huggingface.co/spaces/SemanticTypography/Word-As-Image" target="_blank">
                    > <highlight>Demo</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>


    <div class="portfolio-modal modal fade" id="attend&excite" tabindex="-1" role="dialog" aria-labelledby="attend&excite" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion Models</h1>
                <p class="font-italic mb-3">Hila Chefer*, Yuval Alaluf*, <b>Yael Vinker</b>, Lior Wolf, Daniel Cohen-Or</p>
                <div class="video-container mb-4">
                  <video width="100%" height="auto" id="tree" autoplay controls>
                    <source src="img/portfolio/attend_and_excite_vid.mp4"
                    type="video/mp4">
                  </video>
                </div>
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">Recent text-to-image generative models have demonstrated an unparalleled ability to generate diverse and creative imagery guided by a target text prompt. While revolutionary, current state-of-the-art diffusion models may still fail in generating images that fully convey the semantics in the given text prompt. We analyze the publicly available Stable Diffusion model and assess the existence of catastrophic neglect, where the model fails to generate one or more of the subjects from the input prompt. Moreover, we find that in some cases the model also fails to correctly bind attributes (e.g. colors) to their corresponding subjects. To help mitigate these failure cases, we introduce the concept of Generative Semantic Nursing (GSN), where we seek to intervene in the generative process on the fly during inference time to improve the faithfulness of the generated images. Using an attention- based formulation of GSN, dubbed Attend-and-Excite, we guide the model to refine the cross-attention units to attend to all subject tokens in the text prompt and strengthen — or excite — their activations, encouraging the model to generate all subjects described in the text prompt. We compare our approach to alternative approaches and demonstrate that it conveys the desired concepts more faithfully across a range of text prompts.
                 </p>
                <div class="large mb-2 font-weight-bold">
                  <a href="https://yuval-alaluf.github.io/Attend-and-Excite/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://arxiv.org/abs/2301.13826" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                </div>
              
                <div class="large mb-2 font-weight-bold">
                  <a href="https://github.com/yuval-alaluf/Attend-and-Excite" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

    <div class="portfolio-modal modal fade" id="clipascene" tabindex="-1" role="dialog" aria-labelledby="clipascene" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">CLIPascene: Scene Sketching with Different Types and Levels of Abstraction</h1>
                <p class="font-italic mb-3"><b>Yael Vinker</b>, Yuval Alaluf, Daniel Cohen-Or, Ariel Shamir</p>
                <div class="video-container mb-4">
                  <video width="100%" height="auto" id="tree" autoplay controls>
                    <source src="img/portfolio/clipascene_video1.mp4"
                    type="video/mp4">
                  </video>
                </div>
                
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">In this paper, we present a method for converting a given scene image into a sketch using different types and multiple levels of abstraction. We distinguish between two types of abstraction.
                The first considers the fidelity of the sketch, varying its representation from a more precise portrayal of the input to a looser depiction.
                The second is defined by the visual simplicity of the sketch, moving from a detailed depiction to a sparse sketch.
                Using an explicit disentanglement into two abstraction axes - and multiple levels for each one - provides users additional control over selecting the desired sketch based on their personal goals and preferences.
                To form a sketch at a given level of fidelity and simplification, we train two MLP networks. The first network learns the desired placement of strokes, while the second network learns to gradually remove strokes from the sketch without harming its recognizability and semantics.
                Our approach is able to generate sketches of complex scenes including those with complex backgrounds (e.g., natural and urban settings) and subjects (e.g., animals and people) while depicting gradual abstractions of the input scene in terms of fidelity and simplicity.
                 </p>
                <div class="large mb-2 font-weight-bold">
                  <a href="https://clipascene.github.io/CLIPascene/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://arxiv.org/abs/2211.17256" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                </div>
              
                <div class="large mb-2 font-weight-bold">
                  <a href="https://github.com/yael-vinker/SceneSketch" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="clipasso" tabindex="-1" role="dialog" aria-labelledby="wheelchairLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">CLIPasso: Semantically-Aware Object Sketching</h1>
                <p class="font-italic mb-3"><b>Yael Vinker</b>, Ehsan Pajouheshgar, Jessica Y. Bo, Roman Bachmann, Amit Haim Bermano, Daniel Cohen-Or, Amir Zamir, Ariel Shamir</p>
                  <div class="video-container mb-4">
                  <video width="100%" height="auto" id="tree" autoplay controls>
                    <source src="img/portfolio/clipasso_vid.mp4"
                    type="video/mp4">
                  </video>
                </div>
                
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">Abstraction is at the heart of sketching due to the simple and minimal nature of line drawings. Abstraction entails identifying the essential visual properties of an object or scene, which requires semantic understanding and prior knowledge of high-level concepts. Abstract depictions are therefore challenging for artists, and even more so for machines. We present an object sketching method that can achieve different levels of abstraction, guided by geometric and semantic simplifications. While sketch generation methods often rely on explicit sketch datasets for training, we utilize the remarkable ability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic concepts from sketches and images alike. We define a sketch as a set of Bézier curves and use a differentiable rasterizer to optimize the parameters of the curves directly with respect to a CLIP-based perceptual loss. The abstraction degree is controlled by varying the number of strokes. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual components of the subject drawn. </p>
                <div class="large mb-2 font-weight-bold">
                  <a href="https://clipasso.github.io/clipasso/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://arxiv.org/abs/2202.05822" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                </div>
              
                <div class="large mb-2 font-weight-bold">
                  <a href="https://github.com/yael-vinker/CLIPasso" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>
                <div class="large mb-2 font-weight-bold">
                  <a href="https://replicate.com/yael-vinker/clipasso" target="_blank">
                    > <highlight>Demo</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="deepsim" tabindex="-1" role="dialog" aria-labelledby="visionLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">DeepSIM: Image Shape Manipulation from a Single Augmented Training Sample</h1>
                <p class="font-italic mb-3">Yael Vinker*, Eliahu Horwitz*, Nir Zabari , Yedid Hoshen</p>
                <img class="img-fluid rounded mb-3" src="img/portfolio/3dvision_img.png" alt="">
                
                
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/watch?v=RZwnnttQYzs&t=5s&ab_channel=EliahuHorwitz" frameborder="1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p>We present DeepSIM, a generative model for conditional image manipulation based on a single image. We find that extensive augmentation is key for enabling single image training, and incorporate the use of thin-plate-spline (TPS) as an effective augmentation. Our network learns to map between a primitive representation of the image to the image itself. The choice of a primitive representation has an impact on the ease and expressiveness of the manipulations and can be automatic (e.g. edges), manual (e.g. segmentation) or hybrid such as edges on top of segmentations. At manipulation time, our generator allows for making complex image changes by modifying the primitive input representation and mapping it through the network. Our method is shown to achieve remarkable performance on image manipulation tasks.</p>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://www.vision.huji.ac.il/deepsim/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                </div>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://arxiv.org/pdf/2007.01289.pdf" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                </div>
              
                <div class="large mb-2 font-weight-bold">
                  <a href="https://github.com/eliahuhorwitz/DeepSIM" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>


  <div class="portfolio-modal modal fade" id="hdr" tabindex="-1" role="dialog" aria-labelledby="visionLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Unpaired Learning for High Dynamic Range Image Tone Mapping</h1>
                <p class="font-italic mb-3">Yael Vinker, Inbar Huberman-Spiegelglas, Raanan Fattal</p>
                <img class="img-fluid rounded mb-3" src="img/portfolio/3dvision_img.png" alt="">
                
                

                
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://youtu.be/v2r40TSRr3s" frameborder="1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p>High dynamic range (HDR) photography is becoming increasingly popular and available by DSLR and mobile-phone cameras. While deep neural networks (DNN) have greatly impacted other domains of image manipulation, their use for HDR tone-mapping is limited due to the lack of a definite notion of ground-truth solution, which is needed for producing training data. In this paper we describe a new tone-mapping approach guided by the distinct goal of producing low dynamic range (LDR) renditions that best reproduce the visual characteristics of native LDR images. This goal enables the use of an unpaired adversarial training based on unrelated sets of HDR and LDR images, both of which are widely available and easy to acquire. In order to achieve an effective training under this minimal requirements, we introduce the following new steps and components: (i) a range-normalizing pre-process which estimates and applies a different level of curve-based compression, (ii) a loss that preserves the input content while allowing the network to achieve its goal, and (iii) the use of a more concise discriminator network, designed to promote the reproduction of low-level attributes native LDR possess. Evaluation of the resulting network demonstrates its ability to produce photo-realistic artifact-free tone-mapped images, and state-of-the-art performance on different image fidelity indices and visual distances.</p>

                <div class="large mb-2 font-weight-bold">
                  <a href="https://www.cs.huji.ac.il/w~raananf/projects/hdrgan/" target="_blank">
                    > <highlight>Project website</highlight>
                  </a>
                  <a href="https://arxiv.org/abs/2111.00219" target="_blank">
                    > <highlight>Paper</highlight>
                  </a>
                  <a href="https://github.com/yael-vinker/unpaired_hdr_tmo" target="_blank">
                    > <highlight>Code</highlight>
                  </a>
                </div>
                
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="qnx" tabindex="-1" role="dialog" aria-labelledby="qnxLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">QNX: Obstacle Detection with LiDAR</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/2hacaURM8f8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">LiDAR (light detecting and ranging) devices are commonly used sensors in the automotive market, especially for the development of autonomous vehicles and ADAS (advanced driver-assistance systems). They are reliable for detecting distances of objects in the 3D world, which is useful for computing the location of obstacles and “free space” on the road. Using the speed of light as a reference, LiDARs emit a laser beam and measure the amount of time it takes to receive a return signal, which enables the sensor to perform highly accurate distance calculations. For the purposes of the QNX Advanced Development team, I investigated the usage of LiDAR data for real-time obstacle and free space detection.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Developed perception algorithms for obstacle and free space detection withLiDARs on the QNX sensor framework</li>
                  <li>Created visualizations from fused camera and LiDAR data streams for demonstration at CES 2019</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Gordon Bell (QNX Founder & Researcher)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="attentiv" tabindex="-1" role="dialog" aria-labelledby="attentivLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Attentiv Catheter for IV Treatment</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/FXWrNxUOlpI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>
                
                <h6 class="large font-weight-bold"><highlight>Motivation: </highlight></h6>
                <p>90% of hospital patients get IV infusions, yet up to half of all IV procedures experience some form of failure. IV infiltration happens when IV fluids leak from the vein into tissues, causing damages that can require extended hospitalization, surgeries, and even amputation. Infiltration occurs in 23% of adults and 70% of newborn babies with IVs, and 4-6% of cases result in severe consequences. Hospitals face significant economic burden with $50k treatment costs/patient and the potential of $500k-$2M lawsuits.</p>
                <p>The Attentiv catheter and infiltration monitoring system offers accurate and immediate detection of IV infiltration through its root cause, catheter dislodgement. Our sensor-embedded IV catheter provides real-time localization of the catheter tip and alerts the caretaker team if infiltration occurs. The monitoring system is seamlessly integrated into the existing nursing workflow and IV equipment. For hospitals, we reduce their economic expenditure and elevate their standards of care by preventing severe infiltration injuries.</p>
                <p class="mb-3">Existing devices that aim to address the issue of IV infiltration use non-direct methods for detection . These devices are generally in the form of an external stick-on patch which requires additional dressings to secure and extra wiring, and is not ideal for premature babies with fragile skin. Our device is situated in-vivo and monitors the root cause of infiltration , allowing for quicker responses. Direct sensing allows us to expand into other types of catheters like central lines, where patch sensors cannot detect. Fewer dressings and reduction in protocol changes for nurses has the potential to lead to easier adoption and less costly retraining, which are both significant concerns in healthcare.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Led team through problem discovery and interviews with clinicians </li>
                  <li>Researched biomedical and regulatory standards for safety and compliance</li>
                  <li>Developed sensor processing algorithms to detect adverse IV events</li>
                  <li>Carried out product testing in phantoms and biological tissue</li>
                  <li>Produced video and competition pitches</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Kevin T. (UBC Mechanical Engineering)</li>
                  <li>Rio N. (UBC Integrated Engineering)</li>
                  <li>Gordon Y. (UBC Computer Engineering)</li>
                  <li>Jessica Y. (UBC Sauder School of Business)</li>
                  <li>Siddarth B. (UBC Sauder School of Business)</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Awards: </highlight></h6>
                <ul>
                  <li>James Dyson Awards - National Winner (Canada)</li>
                  <li>James Dyson Awards - International Top 20</li>
                  <li>Medical Device Development Centre of British Columbia - Principle Design Award</li>
                  <li>New Venture Design - Industry Award</li>
                  <li>UBC APSC Design and Innovation Day - Faculty Award</li>
                  <li>Microsoft Discover AI - Healthcare Category Winner</li>
                  <li>UBC Innovation on Board Startup Competition - Runner Up</li> 
                  <li>RBC Get Seeded Pitch Award</li> 
                  <li>New Ventures British Columbia - Semi Finalist</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="certec" tabindex="-1" role="dialog" aria-labelledby="certecLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Interactive Stroke Rehabilitation Wearable</h1>
                <div class="container mb-5">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/certec.gif" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/certec2.gif" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Motivation: </highlight></h6>
                <p>Globally, about 6 million people die from strokes every year. Stroke survivors must undergo extensive physical rehabilitation exercises to recover their motor functions, some of which is done at home after hospital discharge. However, the effectiveness of the rehabilitation is often undermined by the repetitive and uninteresting nature of the exercises, leading to low motivation for the patients to continue the exercises in the long term. Nearly three quarters of stroke survivors report feeling a lack of confidence, and nearly half report a lack of motivation or anger. Over half of all stroke survivors are left with a disability, with a reported 85% suffering from loss of movement in upper limbs. This type of impairment negatively affects the patient’s ability to lead an independent life and perform daily tasks, lowering their quality of life. </p>
                <p class="mb-3">There is a need to improve the effectiveness of at-home rehabilitation in order to cut back on acute care costs as well as to promote patient independence and decrease the reliance on caretakers. This can be done by combining intuitive ergonomic design with necessary rehabilitation exercises to create an interactive interface that patients will enjoy to use. We proposed and prototyped an interactive "glove" rehabilitation device for hand spasticity, a common outcome of stroke. Using Arduino, various sensors, and themoplastic, we constructed and clinically evaluated a functional prototype that provided real-time performance feedback through LEDs and allowed the patient to control a computer game through their therapy exercises.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Investigated interactivity as a method to increase patience compliance in long-term rehabilitation treatments </li>
                  <li>Prototyped a hand spasticity rehabilitation wearable device for stroke survivors</li>
                  <li>Developed sensor processing algorithms to detect hand poses using an Arduino</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Jiaqi L. (UBC Mechanical Engineering)</li>
                  <li>Héctor Caltenco (former Assistant Professor at Lund University)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="fraxure" tabindex="-1" role="dialog" aria-labelledby="fraxureLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">FraXure: Femur Fracture Traction Device</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/5eSBk5gFeGo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <div class="large mb-2 font-weight-bold text-center">
                  <a href="documents/FraXureReport.pdf" target="_blank">
                    > <highlight>Full Project Report</highlight>
                  </a>
                </div>

                <h6 class="large font-weight-bold"><highlight>Motivation: </highlight></h6>
                <p>Globally, between 20 and 50 million people suffer non-fatal injuries as a result of road traffic crashes. Ten percent of road injuries result in a femoral shaft fracture, with the young suffering a disproportionately higher incidence. Such injuries, particularly in low-resource settings, are associated with a high burden of handicap including poor alignment, limb shortening, and knee stiffness.</p>
                <p>For femoral fractures, non-surgical treatment refers to traction, applied via the skin or the skeleton. Traction operates under the primary principle of applying two equal and opposite forces on two fragments of the fracture to achieve and maintain fracture position for healing. Skeletal traction is currently the standard of care for femoral shaft fractures in low and middle income countries (LIMCs). Skeletal traction is unfortunately associated with unwanted medical complications that can prolong treatment period and lowered quality of healing. In traction, insufficient reduction, slippage, or infections can cause malunions. Adverse effects of malunion include functional impairments to gait, limb shortening, and excessive stresses on other joints and body parts.</p>
                <p> The goal of the project was to improve patient outcomes through the design of a cost effective, clinically viable device for the treatment of femur fractures. It was deemed critical that our device offers a non-surgical solution to help alleviate some of the demand for orthopaedic surgeons, whom are scarce in many LMICs as described previously. Without the need for surgical intervention, our hope is that the device will make femur fracture treatment more accessible and affordable for patients. As well, reducing the hospital stay for patients suffering from femur fractures may allow medical resources to be reallocated to the treatment of other injuries, furthe reducing the burden on the healthcare system. As well, mobilizing patients at earlier stages of recovery may present additional social and economic benefits as they can return to their families and return to the workforce earlier.</p>
                <p class="mb-3">Through extensive literature research and in-country consulting with our hospital partners in Uganda and Kenya, we developed a pneumatic traction device that does not require external grounding to the hospital bed, allowing patients to return home with partial mobility. The cushioning system comprises of alternating pressurized airbags that distributes the contact force and reduces risk of deep tissue injuries.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Prototyped testing jigs and mechanical traction device design</li>
                  <li>Researched deep tissue injuries resulting from high pressure contacting interfaces</li>
                  <li>Conducted surface pressure safety testing with prototype</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Members of FraXure from the UBC Biomedical Engineering Student Team </li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Awards: </highlight></h6>
                <ul>
                  <li>International Conference on Engineering Design 2017 - Design Fair Runner Up </li>
                  <li>Medical Device Design Center Excellence Awards - Finalist</li>
                  <li>Rice University 360° Global Health Design Competition - Finalist </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="haptic" tabindex="-1" role="dialog" aria-labelledby="hapticLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">H4ptic: Sensory Feedback Wearable</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/zJf1ysjxdwo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <h6 class="large font-weight-bold"><highlight>Motivation: </highlight></h6>
                <p class="mb-3">There is limited usability in today's current prosthetic devices as they do not offer haptic sensory feedback. Modular EMG prosthetics are becoming increasingly common. Although the functionality of these prosthetics depends greatly on feedback to the user, this is an area where there has been limited development. To resolve this problem, we created H4ptic, a non-invasive device that captures haptic sensation from the prosthetic and transmits that sensation to the user’s body. H4ptic was designed using the principles of somatosensory cortex remapping, neuroplasticity, and sensory substitution. </p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Reviewed literature on somatosensory cortex remapping in application to sensory feedback for upper limb amputees</li>
                  <li>Produced project video and competition project pitch</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Jacob B. (UBC Occupational Therapy)</li>
                  <li>Miriam W. (UBC Cognitive Systems)</li>
                  <li>Maria P. (UBC Engineering Physics)</li>
                  <li>Allan N. (UBC Mechanical Engineering)</li>
                  <li>Justin W. (UBC Biomedical Engineering)</li>
                  <li>Madison M. (UBC Electrical Engineering)</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Awards: </highlight></h6>
                <ul>
                  <li>Hatching Health Hackathon- Best Technical Innovation </li>
                  <li>Speak Out for Engineering - Vancouver Regional Winner</li>
                  <li>Speak Out for Engineering - Americas Winner </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="recrutch" tabindex="-1" role="dialog" aria-labelledby="recrutchLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">ReCrutch: Reimagined Crutches</h1>
                <div class="container mb-5">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/recrutch_img.jpg" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/recrutch_img2.png" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Motivation: </highlight></h6>
                <p class="mb-3">This project was inspired after I witnessed a friend on crutches struggling to navigate flights of stairs. The rigid, vertical design of traditional crutches exert high pressure at contact points (palms and underarms) for users, making it an uncomfortable device to use for prolonged durations. Additionally, the inflexibility of the crutch hinders natural gait when traversing stairs. In my redesign, the ReCrutch features a retractable duel-handle design that aids the user while both ascending and descending stairs, simply by reversing the holding direction. The flexible S-shaped body also acts as a shock absorber. The elbow cradle is an ergonomic feature that helps relieve underarm contact pressure.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Took inspiration from ergonomic principles to redesign the load-bearing mechanism of the crutch</li>
                  <li>Produced conceptual sketches and implemented design using Fusion 360 CAD</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="emr" tabindex="-1" role="dialog" aria-labelledby="emrLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Electronical Medical Records Systems</h1>
                <div class="video-container mb-3">
                  <iframe width="560" height="315" src="documents/EMRPoster.pdf" frameborder="0"></iframe>
                </div>
                <p class="font-italic mb-3">Gwara, M, Tsang, VL, Thompson, CA, Smith, S, <highlight>Bo, J</highlight>, Fletcher, S, Janusz, N, Chew, SY, Janusz, M, Thompson, CK, Bertrand, M, Woods, H, Thompson, C (2018). Use of Centralized Electronic Medical Records System in Paediatric Care. In American Academy of Pediatrics 2017.</p>
                
                <h6 class="large font-weight-bold"><highlight>Abstract: </highlight></h6>
                <p class="mb-3">Centralized Electronic Medical Record systems (EMR) have potential to provide a variety of benefits to national healthcare systems worldwide. However, their implementation has proven to be challenging and raised several concerns. Although previous work has analyzed the successes and limitations of centralized EMR systems, statistical analysis to quantify user perspective has not yet been conducted. In order to gain a better understanding of the opinions of medical professionals and others in the field regarding their perceived support, benefits, and barriers for a centralized EMR system, a survey was conducted on the participants of the International Paediatrics Association (IPA) 2016 Conference in Vancouver, BC. The survey contained Likert Scale questions, asking participants to rate the importance of listed benefits and barriers, as well as indicate their overall support for centralized EMR systems on a scale of 1 to 5. The data was analyzed using a one-way ANOVA, with a focus on the countries with the greatest number of respondents (USA, Canada, Nigeria, and Mexico). The responses were also categorized and analyzed based on country development. The results indicated that Mexico, as well as other non-developed countries were shown to be most in favour of the EMR system. Fast record access and efficiency were rated as the most significant benefits of a centralized EMR system, while cost and implementation time were perceived as the largest barriers. Implementation time was also rated significantly higher as a barrier by developed countries than non-developed countries. These findings provide useful guidelines for consideration in the implementation of a centralized EMR system, and help in the drive towards improving national healthcare systems worldwide.</p>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Collected Likert survey responses from physicians at an international paediatrics conference</li>
                  <li>Analyzed statistical significance in attitudes towards EMR systems using R</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Members of the International Children's Advisory Network (authors listed in publication)</li>
                </ul>

              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="heelevator" tabindex="-1" role="dialog" aria-labelledby="heelevatorLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Automated Heel Raiser for Skiing </h1>
                <div class="container mb-5">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/sad_skier.PNG" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/happy_skier.PNG" /> 
                    </div>
                  </div>
                </div>
                <h6 class="large font-weight-bold"><highlight>Project Summary: </highlight></h6>
                <p class="mb-3">In a class project, our team of six Mechanical Engineering students were challenged to provide a custom designed solution for a fictictious customer. "FreeBoots Enterprises" discusses their interest for the design of a device that is ideally lightweight, portable, and mechatronics-based to assist backcountry skiers with their uphill ascents. The device is expected to increase the number of ascents in a day or reduce the net effort required to ascend. This may be accomplished by reducing the amount of time required to ascend, reducing the metabolic energy required from the skier to ascend, or redirecting forces from the parts of the body that are used most when ascending to other areas. The device could also reduce the net effort to ascend by decreasing the overall weight of the gear to be carried by the skier by having the device replace other pieces of equipment, by decreasing the energy lost due to friction from the skins, or by lifting the skis out of the snow during strides. The device should not reduce the effectiveness of safety gear, increase the risk of an avalanche, and impede the motion of the skier should an avalanche occur.</p>

                <div class="container mb-3">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/concepts.jpg" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/upper_exo.jpg" /> 
                    </div>
                  </div>
                </div>

                <p class="mb-3">After iterating through many concepts, we selected a design that is simple and light-weight to attach to existing ski equipment. The automated heel raiser is derived from the mechanical heel raiser used by many backcountry skiiers in their routine. However, it comes with the benefit of auto adjustments that raise the heel correspondingly to the incline of the slope. This results in optimal reduction in energy, as either an over elongation (not raised high enough) or over contraction (raised too high) in the calf muscles would diminish the energy efficiency of the muscles.</p>

                <div class="container mb-5">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/heelevator.png" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/ski.png" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Analyzed the reduction in energy expenditure in uphill backcountry ascent using the product</li>
                  <li>Generated and evaluated various design concepts using </li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Daniel G. (UBC Mechanical Engineering)</li>
                  <li>Jenny C. (UBC Mechanical Engineering)</li>
                  <li>Jordan F. (UBC Mechanical Engineering)</li>
                  <li>Martin F. (UBC Mechanical Engineering)</li>
                  <li>Cody S. (UBC Mechanical Engineering)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="fireboat" tabindex="-1" role="dialog" aria-labelledby="fireboatLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Remote-Controlled Fireboat </h1>
                <div class="container mb-5">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/fireboat.png" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/fireboat2.png" /> 
                    </div>
                  </div>
                </div>
                <h6 class="large font-weight-bold"><highlight>Project Summary: </highlight></h6>
                <p>The Marine Emergency Response Group (MERG) requires a fireboat to respond to fires in the coastal waters. Vessel requirements include high speed, agile maneuverability, accurate delivery of pressurized payload, and construction using sustainable materials. Bonus points are given to a boat with a well-designed aesthetic.</p>

                <p class="mb-4">Our team choose a double catamaran boat design to optimize for speed. Pressurized water, reflective of the firefighting capacity of fireboats, is released through the control of servo motors and an Arduino. The boat is constructed from sustainable materials, including a cardboard based replica of a certain Pokemon. We simulated the water spray trajectories and boat speeds to best prepare for evaluation.</p>

                <div class="container mb-3">
                  <div class="row justify-content-center">
                    <div class="col-lg-10">
                      <img class="img-fluid" src="img/portfolio/fireboat_nozzle.png" align="left" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Conducted speed, agility, and drag tests to simulate the boat motion with MATLAB</li>
                  <li>Created aesthetic design as inspired by Squirtle, a water pokemon</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Charles L. (UBC Mechanical Engineering)</li>
                  <li>Noemie J. (UBC Mechanical Engineering)</li>
                  <li>Cristian M. (UBC Mechanical Engineering)</li>
                  <li>Duk L. (UBC Mechanical Engineering)</li>
                  <li>Karl E. (UBC Mechanical Engineering)</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Awards: </highlight></h6>
                <ul>
                  <li>MECH 223 Competition - First Place Speed</li>
                  <li>MECH 223 Competition - Public Voted Best Design</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="regen" tabindex="-1" role="dialog" aria-labelledby="regenLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Regenerative Braking Car </h1>
                <div class="container">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/regen.png" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/regen2.png" /> 
                    </div>
                  </div>
                </div>
                <h6 class="large font-weight-bold"><highlight>Project Summary: </highlight></h6>
                <p>Green Vehicles Canada (GVC) requires an autonomous vehicle capable of recovering braking energy. Requirements include ability to stop and resume movement, controlled descending speed, and cargo storage while maximizing travel distance.</p>

                <p class="mb-4">The primary energy storage is a flywheel that stores angular momentum through rotation of the rear axle. A gearbox pivots about axle to engage and disengage flywheel through a differential drivetrain. The secondary energy storage is a mass and pulley system which maintains potential energy by raising the mass through axle rotation during the "braking" </p>

                <div class="container">
                  <div class="row justify-content-center">
                    <div class="col-lg-10">
                      <img class="img-fluid" src="img/portfolio/regen_energy.png" align="left" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Programmed Arduino code to control the activation of regenerative braking </li>
                  <li>Brainstormed dual-energy storage concept and calculated energy efficiency</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Charles L. (UBC Mechanical Engineering)</li>
                  <li>Noemie J. (UBC Mechanical Engineering)</li>
                  <li>Cristian M. (UBC Mechanical Engineering)</li>
                  <li>Duk L. (UBC Mechanical Engineering)</li>
                  <li>Karl E. (UBC Mechanical Engineering)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="orbit" tabindex="-1" role="dialog" aria-labelledby="orbitLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">ORBIT Cubesat</h1>

                <div class="container">
                  <div class="row justify-content-center">
                    <div class="col-lg-7">
                      <img class="img-fluid" src="img/portfolio/thunderbird.png" align="middle"/> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Project Summary: </highlight></h6>
                <p class="mb-3">The Thunderbird Satellite's primary payload consists of two cameras intended for high-resolution imaging of Earth. The photos are evaluated for potential forest fire risks using on-board machine learning modules, trained on the ground, with capability to update these modules over the course of the mission. The use of two cameras enables multiple filters to be applied to the image sensor, allowing for infrared and visible light imaging.</p>

                <div class="container">
                  <div class="row justify-content-center">
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/antenna.png" align="left" /> 
                    </div>
                    <div class="col-lg-5">
                      <img class="img-fluid" src="img/portfolio/orbit_diagram.PNG" /> 
                    </div>
                  </div>
                </div>

                <h6 class="large font-weight-bold"><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Created CAD models of components used for the structural team</li>
                  <li>Simulated the path and rotation of the satellite around the sub on MATLAB for the controls team</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Members of the UBC ORBIT team</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="hololabel" tabindex="-1" role="dialog" aria-labelledby="hololabelLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">HoloLabel: AR Scene Annotator</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/K0sVDIbSMh4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <div class="large mb-2 font-weight-bold text-center">
                  <a href="documents/Mixed_Reality_final_report.pdf" target="_blank">
                    > <highlight>Paper (Class Submission)</highlight>
                  </a>
                </div>

                <h6 class="large font-weight-bold "><highlight>Motivation: </highlight></h6>
                <p> As the popularity of supervised and semi-supervised learning tasks in embodied perception rises, so does the demand for large-scale annotated 3D scene datasets. Devices equipped with RGB cameras and depth sensors being readily available simplifies the task of capturing and reconstructing an environment as a 3D mesh. However, the task of manually labelling this 3D data is still non-trivial. To obtain semantic information about the scene, experts often have to work for many hours using non-intuitive and error-prone tools. To address this problem, we propose a HoloLens application to allow a user to directly annotate the scene with semantic information while simultaneously capturing the spatial environment mesh. Our tool focuses on 3D mesh-based semantic segmentation, i.e. annotating areas of the scene using a predefined set of classes. We leverage the HoloLens' Spatial Mapping feature to generate a 3D mesh of the scene and apply an automatic segmentation algorithm to generate segmentation proposals. The user can use a virtual paint brush to refine the segments or create new ones. Finally, we allow the option to add richer semantic descriptions using voice-to-text technology. We aim to lay the groundwork to integrate mixed reality devices in enabling intuitive 3D scene annotation in the real world.
                </p>

                <h6 class="large font-weight-bold "><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Developed augmented reality user interface with Mixed Reality Toolkit (MRTK) for HoloLens</li>
                  <li>Designed user test to assess efficiency of using the tool and the accuracy of annotation</li>
                  <li>Created a video tutorial for user study participants </li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Janik L. (ETH Zurich INFK)</li>
                  <li>Dhruv A. (ETH Zurich INFK)</li>
                  <li>Veronique K. (ETH Zurich INFK)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="forest" tabindex="-1" role="dialog" aria-labelledby="forestLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Into the Forest: Immersive Game</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/q1nEGKHzwJc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <div class="large mb-2 font-weight-bold text-center">
                  <a href="intotheforest.html" target="_blank">
                    > <highlight>Play the Game Demo!</highlight>
                  </a>
                </div>

                <h6 class="large font-weight-bold "><highlight>Motivation: </highlight></h6>
                <p>Achieving full immersion in gaming is difficult but desirable for player engagement. Despite being limited by computation power and the lack of AR/VR hardware, we nevertheless wanted to create an immersive and artistic gaming experience. Moreover, we try to shift the player's emotions from the start to the end of the game by creating gradually crescendoing tension and urgency. We focused on creating the visual and sound systems, as 80% of environmental information comes from vision and 15% comes from hearing. This, "Into the Forest", a first-person escape game set in a cheerfully deceptive forest, was born:</p>
                <p class="font-italic text-center">You wake up in the middle of a forest, no memories of how you got here. But somehow it feels like you’ve been floating through these woods for a long time now. With birdsongs in the background and the sun high, the forest feels alive. Something in the air seems off, however. A tinge of mystery. Well, nothing to do but to venture further. There must be someway home. But soon the bird calls cease, a wispy mist floats, around and into you. Dark clouds blot the sky. Thick clouds infect your mind. Something the air seems off. </p>
                <p class="mb-3 font-italic text-center">The forest feels alive.</p>

                <h6 class="large font-weight-bold "><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Brainstormed game storyboard and developed early moodboard and concept art</li>
                  <li>Created various low-poly nature assets with Blender</li>
                  <li>Programatically controlled lighting, scene layout, asset arrangement, skybox effects, fog rendering, and win/lose conditions in Unity </li>
                  <li>Collected beta tester feedback and added requested improvements to the game </li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Kevin T. (ETH Zurich Robotics)</li>
                  <li>Andyn O. (Empa)</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="myohome" tabindex="-1" role="dialog" aria-labelledby="myohomeLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">MyoHome: Gesture-Controlled Smarthome</h1>
                <div class="video-container mb-4">
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/f6Xtxq86wmA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </div>

                <h6 class="large font-weight-bold "><highlight>Motivation: </highlight></h6>
                <p class="mb-3">Modern smarthomes are typically voice-controlled, which presents a detriment to potential users with speech impairments or strong accents. We turned to the Myo Armband, an non-invasive EMG sensing device that comes with pre-built abilities to recognize simple hand gestures. Instead of speaking to Alexa or Google Home, users can control their smart home devices such as lights and fans at the flick of their wrist and arm. Based on how many devices there are, users can use the MyoHome web app to configure the gestures for each device, and save those customized gestures to a user profile. Although there are only 5 basic gestures built in to the Myo Connect app, there are essentially an infinite number of gestures that could be configured based on the raw data output from the accelerometer, EMG sensors, and gyroscope.</p>

                <h6 class="large font-weight-bold "><highlight>Responsibilities: </highlight></h6>
                <ul>
                  <li>Brainstormed design and business motivation for a gesture controlled smarthome</li>
                  <li>Designed and assembled physical prototype and mock appliances</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Collaborators: </highlight></h6>
                <ul>
                  <li>Ian K. (UBC Mechanical Engineering)</li>
                  <li>Nicholas H. (UBC Mechanical Engineering)</li>
                  <li>Stephen L. (UBC Computer Science)</li>
                </ul>

                <h6 class="large font-weight-bold"><highlight>Awards: </highlight></h6>
                <ul>
                  <li>nwHacks 2018 Honourable Mention</li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="portfolio-modal modal fade" id="postcards" tabindex="-1" role="dialog" aria-labelledby="postcardsLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Postcards & Sketches</h1>
                  <div id="postcardCarousel" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#postcardCarousel" data-slide-to="0" class="active"></li>
                        <li data-target="#postcardCarousel" data-slide-to="1"></li>
                        <li data-target="#postcardCarousel" data-slide-to="2"></li>
                        <li data-target="#postcardCarousel" data-slide-to="3"></li>
                        <li data-target="#postcardCarousel" data-slide-to="4"></li>
                        <li data-target="#postcardCarousel" data-slide-to="5"></li>
                        <li data-target="#postcardCarousel" data-slide-to="6"></li>
                        <li data-target="#postcardCarousel" data-slide-to="7"></li>
                        <li data-target="#postcardCarousel" data-slide-to="8"></li>
                        <li data-target="#postcardCarousel" data-slide-to="9"></li>
                        <li data-target="#postcardCarousel" data-slide-to="10"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-100" src="img/portfolio/postcards/otaru_street.jpeg" alt="Otaru street">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Street in Otaru, Hokkaido, Japan </fulllight></h5>
                                <p>(43.194092, 141.002771)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/otaru_canal.jpeg" alt="Otaru canal">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Canal in Otaru, Hokkaido, Japan </fulllight></h5>
                                <p>(43.199914, 141.001594)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/tokyo.jpg" alt="Tokyo intersection">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Underpass in Shinjuku City, Tokyo, Japan </fulllight></h5>
                                <p>(35.701311, 139.700744)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/nishiki.jpeg" alt="Nishiki Market">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Seafood stall in Nishki Market, Kyoto, Japan </fulllight></h5>
                                <p>(35.004882, 135.764916)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/golden_pass.jpeg" alt="Golden Pass Railway">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Golden Pass Railway near Saanen, Bern, Switzerland </fulllight></h5>
                                <p>(46.491337, 7.280064)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/annecy.jpeg" alt="Annecy Old Town">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Vieille Ville de Annecy, Haute-Savoie, France </fulllight></h5>
                                <p>(45.898848, 6.125080)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/paris.jpeg" alt="Passage des Panoramas">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Passage des Panoramas in Paris, Île-de-France, France </fulllight></h5>
                                <p>(48.870608, 2.341582)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/oslo.jpeg" alt="Akrobaten Bridge">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Akrobaten Bridge in Oslo, Norway </fulllight></h5>
                                <p>(59.910171, 10.760282)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/athens.jpeg" alt="Peek a Bloom in Athens">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Peek a Bloom in Athens, Greece </fulllight></h5>
                                <p>(37.976883, 23.731930)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/porto.jpeg" alt="Kittie Point Rock in Porto">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Kittie Point Rock in Porto, Portugal </fulllight></h5>
                                <p>(41.139156, -8.607268)</p>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/postcards/lisbon.jpeg" alt="Streets of Alfama in Lisbon">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Alfama District in Lisbon, Portugal </fulllight></h5>
                                <p>(38.71260, -9.135844)</p>
                            </div>
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#postcardCarousel" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#postcardCarousel" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>

                <p class="mt-4 mb-3 font-italic text-center">If you're interested in commisioning a postcard sketch, contact me!</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div> 

  <div class="portfolio-modal modal fade" id="tattoos" tabindex="-1" role="dialog" aria-labelledby="tattoosLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Handpokes</h1>
                  <div id="tattooCarousel" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#tattooCarousel" data-slide-to="0" class="active"></li>
                        <li data-target="#tattooCarousel" data-slide-to="1"></li>
                        <li data-target="#tattooCarousel" data-slide-to="2"></li>
                        <li data-target="#tattooCarousel" data-slide-to="3"></li>
                        <li data-target="#tattooCarousel" data-slide-to="4"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-100" src="img/portfolio/tattoos/fable.jpeg" alt="Tattoo of Fable">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><highlight> fable </highlight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/tattoos/bust.jpeg" alt="Tattoo of a Greek bust">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><highlight> marbled </highlight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/tattoos/leaf.jpg" alt="Tattoo of leaf">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><highlight> spring sprig </highlight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/tattoos/mountain.jpg" alt="Tattoo of mountain">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><highlight>  minimal mountains  </highlight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/tattoos/arrow.jpg" alt="Tattoo of arrows">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><highlight>  ups and downs  </highlight></h5>
                            </div>
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#tattooCarousel" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#tattooCarousel" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div> 

  <div class="portfolio-modal modal fade" id="otherart" tabindex="-1" role="dialog" aria-labelledby="otherartLabel" aria-hidden="true">
    <div class="modal-dialog modal-xl" role="document">
      <div class="modal-content">
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">
            <i class="fas fa-times fa-xs"></i>
          </span>
        </button>
        <div class="modal-body">
          <div class="container">
            <div class="row justify-content-center">
              <div class="col-lg-10">
                <h1 class="portfolio-modal-title mb-4 text-center">Misc. Artwork</h1>
                  <div id="artCarousel" class="carousel slide" data-ride="carousel">
                    <ol class="carousel-indicators">
                        <li data-target="#artCarousel" data-slide-to="0" class="active"></li>
                        <li data-target="#artCarousel" data-slide-to="1"></li>
                        <li data-target="#artCarousel" data-slide-to="2"></li>
                        <li data-target="#artCarousel" data-slide-to="3"></li>
                        <li data-target="#artCarousel" data-slide-to="4"></li>
                        <li data-target="#artCarousel" data-slide-to="5"></li>
                    </ol>
                    <div class="carousel-inner">
                        <div class="carousel-item active">
                            <img class="d-block w-100" src="img/portfolio/otherart/sandstorm.png" alt="Oil painting">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> sandstorm </fulllight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/otherart/sublime.JPG" alt="Acrylic painting">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> "A Sublime Night Out With My Step-Parents" </fulllight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/otherart/ponti.png" alt="Digital painting">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> Ponti del Salti (unfinished)</fulllight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/otherart/lisa.png" alt="Coloured pencil drawing">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> throwback to the 2010s </fulllight></h5>
                            </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/otherart/protect(attack).png" alt="Digital art">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> fable </fulllight></h5>
                            </div>
                        </div>
                        </div>
                        <div class="carousel-item">
                            <img class="d-block w-100" src="img/portfolio/otherart/flower.png" alt="Coloured pencil drawing">
                            <div class="carousel-caption d-none d-md-block">
                                <h5><fulllight> fleur </fulllight></h5>
                            </div>
                        </div>
                    </div>
                    <a class="carousel-control-prev" href="#artCarousel" role="button" data-slide="prev">
                        <span class="carousel-control-prev-icon" aria-hidden="true"></span>
                        <span class="sr-only">Previous</span>
                    </a>
                    <a class="carousel-control-next" href="#artCarousel" role="button" data-slide="next">
                        <span class="carousel-control-next-icon" aria-hidden="true"></span>
                        <span class="sr-only">Next</span>
                    </a>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div> 


<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>


</body>

</html>
